{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pan20.fake import inputs\n",
    "#from pan20.fake import features\n",
    "from pan20 import fake\n",
    "\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "#from string import punctuation\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords \n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data = inputs.parse('data/pan20-author-profiling-training-2020-02-23.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = fake.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "truth = {x['author']: x['label'] for x in fake.load_truth()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['label'] = df.author.apply(lambda x: truth[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class PreProcessTweets:\n",
    "#     def __init__(self):\n",
    "#         self._stopwords = set(stopwords.words('english') + list(punctuation) + ['AT_USER','URL'])\n",
    "        \n",
    "#     def processTweets(self, list_of_tweets):\n",
    "#         processedTweets=[]\n",
    "#         for tweet in list_of_tweets:\n",
    "#             processedTweets.append((self._processTweet(tweet)))\n",
    "#         return processedTweets\n",
    "    \n",
    "#     def _processTweet(self, tweet):\n",
    "#         tweet = tweet.lower() # convert text to lower-case\n",
    "#         tweet = re.sub('((www\\.[^\\s]+)|(https?://[^\\s]+))', 'URL', tweet) # remove URLs\n",
    "#         #tweet = re.sub('@[^\\s]+', 'AT_USER', tweet) # remove usernames\n",
    "#         tweet = re.sub(r'#([^\\s]+)', r'', tweet) # remove the # in #hashtag\n",
    "#         tweet = word_tokenize(tweet) # remove repeated characters (helloooooooo into hello)\n",
    "#         return [word for word in tweet if word not in self._stopwords]\n",
    "# tweetProcessor = PreProcessTweets()\n",
    "# preprocessedTrainingSet = tweetProcessor.processTweets(df['tweet'])\n",
    "\n",
    "def remove_emoji(string):\n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "                           u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "                           u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "                           u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "                           u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                           u\"\\U00002702-\\U000027B0\"\n",
    "                           u\"\\U000024C2-\\U0001F251\"\n",
    "                           \"]+\", flags=re.UNICODE)\n",
    "    return emoji_pattern.sub(r'', string)\n",
    "\n",
    "def remove_hashtag(string):\n",
    "    hashtag_pattern = re.compile(\"#([^\\s]+)\")\n",
    "    \n",
    "    return re.sub(' {2,}', '', hashtag_pattern.sub(r'', string))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['tweet'] = df['tweet'].apply(remove_emoji)\n",
    "df['tweet'] = df['tweet'].apply(remove_hashtag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(tokenizer=word_tokenize, analyzer='word', ngram_range=(1,2), stop_words = None, smooth_idf=True, sublinear_tf=True, norm='l2')\n",
    "#tfidf = TfidfVectorizer(tokenizer=identity_tokenizer, analyzer='word', ngram_range=(1,2), stop_words = None, smooth_idf=True, sublinear_tf=True, norm='l2', lowercase=False, token_pattern='(?u)\\\\b\\\\w\\\\w*\\\\b')\n",
    "#tfidf.fit(df[0])\n",
    "train_df['tweet'] = tfidf.fit_transform(train_df['tweet'])\n",
    "test_df['tweet'] = tfidf.transform(test_df['tweet'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 37.1 GiB for an array with shape (24000, 207281) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-74-396093bb1555>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mtrain_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'tweet'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'tweet'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.7/site-packages/scipy/sparse/compressed.py\u001b[0m in \u001b[0;36mtoarray\u001b[0;34m(self, order, out)\u001b[0m\n\u001b[1;32m   1022\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0morder\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1023\u001b[0m             \u001b[0morder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_swap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cf'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1024\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_toarray_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1025\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_contiguous\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf_contiguous\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1026\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Output array must be C or F contiguous'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.7/site-packages/scipy/sparse/base.py\u001b[0m in \u001b[0;36m_process_toarray_args\u001b[0;34m(self, order, out)\u001b[0m\n\u001b[1;32m   1184\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1185\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1186\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1187\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMemoryError\u001b[0m: Unable to allocate 37.1 GiB for an array with shape (24000, 207281) and data type float64"
     ]
    }
   ],
   "source": [
    "for i in range(len(train_df)):\n",
    "    train_df['tweet'][i] = train_df['tweet'][i].toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'toarray' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-71-43a3e19865da>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'tweet'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'tweet'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'toarray' is not defined"
     ]
    }
   ],
   "source": [
    "train_df['tweet'] = train_df['tweet'].apply(toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50         (0, 203211)\\t0.1515247440751767\\n  (0, 19860...\n",
       "98         (0, 203211)\\t0.1515247440751767\\n  (0, 19860...\n",
       "37         (0, 203211)\\t0.1515247440751767\\n  (0, 19860...\n",
       "62         (0, 203211)\\t0.1515247440751767\\n  (0, 19860...\n",
       "1          (0, 203211)\\t0.1515247440751767\\n  (0, 19860...\n",
       "95         (0, 203211)\\t0.1515247440751767\\n  (0, 19860...\n",
       "70         (0, 203211)\\t0.1515247440751767\\n  (0, 19860...\n",
       "97         (0, 203211)\\t0.1515247440751767\\n  (0, 19860...\n",
       "45         (0, 203211)\\t0.1515247440751767\\n  (0, 19860...\n",
       "6          (0, 203211)\\t0.1515247440751767\\n  (0, 19860...\n",
       "94         (0, 203211)\\t0.1515247440751767\\n  (0, 19860...\n",
       "68         (0, 203211)\\t0.1515247440751767\\n  (0, 19860...\n",
       "53         (0, 203211)\\t0.1515247440751767\\n  (0, 19860...\n",
       "91         (0, 203211)\\t0.1515247440751767\\n  (0, 19860...\n",
       "89         (0, 203211)\\t0.1515247440751767\\n  (0, 19860...\n",
       "55         (0, 203211)\\t0.1515247440751767\\n  (0, 19860...\n",
       "96         (0, 203211)\\t0.1515247440751767\\n  (0, 19860...\n",
       "67         (0, 203211)\\t0.1515247440751767\\n  (0, 19860...\n",
       "58         (0, 203211)\\t0.1515247440751767\\n  (0, 19860...\n",
       "40         (0, 203211)\\t0.1515247440751767\\n  (0, 19860...\n",
       "117        (0, 203211)\\t0.1515247440751767\\n  (0, 19860...\n",
       "132        (0, 203211)\\t0.1515247440751767\\n  (0, 19860...\n",
       "184        (0, 203211)\\t0.1515247440751767\\n  (0, 19860...\n",
       "110        (0, 203211)\\t0.1515247440751767\\n  (0, 19860...\n",
       "105        (0, 203211)\\t0.1515247440751767\\n  (0, 19860...\n",
       "179        (0, 203211)\\t0.1515247440751767\\n  (0, 19860...\n",
       "199        (0, 203211)\\t0.1515247440751767\\n  (0, 19860...\n",
       "126        (0, 203211)\\t0.1515247440751767\\n  (0, 19860...\n",
       "102        (0, 203211)\\t0.1515247440751767\\n  (0, 19860...\n",
       "155        (0, 203211)\\t0.1515247440751767\\n  (0, 19860...\n",
       "                               ...                        \n",
       "29859      (0, 203211)\\t0.1515247440751767\\n  (0, 19860...\n",
       "29814      (0, 203211)\\t0.1515247440751767\\n  (0, 19860...\n",
       "29883      (0, 203211)\\t0.1515247440751767\\n  (0, 19860...\n",
       "29818      (0, 203211)\\t0.1515247440751767\\n  (0, 19860...\n",
       "29815      (0, 203211)\\t0.1515247440751767\\n  (0, 19860...\n",
       "29831      (0, 203211)\\t0.1515247440751767\\n  (0, 19860...\n",
       "29852      (0, 203211)\\t0.1515247440751767\\n  (0, 19860...\n",
       "29833      (0, 203211)\\t0.1515247440751767\\n  (0, 19860...\n",
       "29861      (0, 203211)\\t0.1515247440751767\\n  (0, 19860...\n",
       "29893      (0, 203211)\\t0.1515247440751767\\n  (0, 19860...\n",
       "29915      (0, 203211)\\t0.1515247440751767\\n  (0, 19860...\n",
       "29982      (0, 203211)\\t0.1515247440751767\\n  (0, 19860...\n",
       "29972      (0, 203211)\\t0.1515247440751767\\n  (0, 19860...\n",
       "29977      (0, 203211)\\t0.1515247440751767\\n  (0, 19860...\n",
       "29979      (0, 203211)\\t0.1515247440751767\\n  (0, 19860...\n",
       "29932      (0, 203211)\\t0.1515247440751767\\n  (0, 19860...\n",
       "29986      (0, 203211)\\t0.1515247440751767\\n  (0, 19860...\n",
       "29998      (0, 203211)\\t0.1515247440751767\\n  (0, 19860...\n",
       "29943      (0, 203211)\\t0.1515247440751767\\n  (0, 19860...\n",
       "29969      (0, 203211)\\t0.1515247440751767\\n  (0, 19860...\n",
       "29994      (0, 203211)\\t0.1515247440751767\\n  (0, 19860...\n",
       "29976      (0, 203211)\\t0.1515247440751767\\n  (0, 19860...\n",
       "29935      (0, 203211)\\t0.1515247440751767\\n  (0, 19860...\n",
       "29903      (0, 203211)\\t0.1515247440751767\\n  (0, 19860...\n",
       "29989      (0, 203211)\\t0.1515247440751767\\n  (0, 19860...\n",
       "29997      (0, 203211)\\t0.1515247440751767\\n  (0, 19860...\n",
       "29920      (0, 203211)\\t0.1515247440751767\\n  (0, 19860...\n",
       "29985      (0, 203211)\\t0.1515247440751767\\n  (0, 19860...\n",
       "29938      (0, 203211)\\t0.1515247440751767\\n  (0, 19860...\n",
       "29963      (0, 203211)\\t0.1515247440751767\\n  (0, 19860...\n",
       "Name: tweet, Length: 6000, dtype: object"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df['tweet']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_feats = [c for c in df.columns if c not in ['author', 'label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x_train = train[x_feats].values\n",
    "#x_test = test[x_feats].values\n",
    "y_train= train['label'].values\n",
    "#y_test = test['label'].values\n",
    "y_test = df.drop(train.index)['label'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = GaussianNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB(priors=None, var_smoothing=1e-09)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(x_train_tfidf.toarray(), y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = clf.predict(x_test_tfidf.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7515"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## using len(data)=10000\n",
    "\n",
    "np.mean(predictions == y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.731"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## using len(data)=15000\n",
    "\n",
    "np.mean(predictions == y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/_function_transformer.py:97: FutureWarning: The default validate=True will be replaced by validate=False in 0.22.\n",
      "  \"validate=False in 0.22.\", FutureWarning)\n",
      "/usr/local/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/_function_transformer.py:97: FutureWarning: The default validate=True will be replaced by validate=False in 0.22.\n",
      "  \"validate=False in 0.22.\", FutureWarning)\n",
      "/usr/local/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/_function_transformer.py:97: FutureWarning: The default validate=True will be replaced by validate=False in 0.22.\n",
      "  \"validate=False in 0.22.\", FutureWarning)\n",
      "/usr/local/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/_function_transformer.py:97: FutureWarning: The default validate=True will be replaced by validate=False in 0.22.\n",
      "  \"validate=False in 0.22.\", FutureWarning)\n",
      "/usr/local/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/_function_transformer.py:97: FutureWarning: The default validate=True will be replaced by validate=False in 0.22.\n",
      "  \"validate=False in 0.22.\", FutureWarning)\n",
      "/usr/local/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/_function_transformer.py:97: FutureWarning: The default validate=True will be replaced by validate=False in 0.22.\n",
      "  \"validate=False in 0.22.\", FutureWarning)\n",
      "/usr/local/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/_function_transformer.py:97: FutureWarning: The default validate=True will be replaced by validate=False in 0.22.\n",
      "  \"validate=False in 0.22.\", FutureWarning)\n",
      "/usr/local/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/_function_transformer.py:97: FutureWarning: The default validate=True will be replaced by validate=False in 0.22.\n",
      "  \"validate=False in 0.22.\", FutureWarning)\n",
      "/usr/local/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/_function_transformer.py:97: FutureWarning: The default validate=True will be replaced by validate=False in 0.22.\n",
      "  \"validate=False in 0.22.\", FutureWarning)\n",
      "/usr/local/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/_function_transformer.py:97: FutureWarning: The default validate=True will be replaced by validate=False in 0.22.\n",
      "  \"validate=False in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.545      0.54433333 0.52083333 0.58833333 0.52183333]\n",
      "0.5440666666666667\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-3f50332e8b01>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'X' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "\n",
    "clf = Pipeline([('vect', TfidfVectorizer()),\n",
    "                ('funct', FunctionTransformer(lambda x: x.todense(), accept_sparse=True)),\n",
    "                ('gnb', GaussianNB())])\n",
    "\n",
    "scores = cross_val_score(clf, df['tweet'].values, df['label'], cv=5)\n",
    "print(scores)\n",
    "print(np.mean(scores))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
