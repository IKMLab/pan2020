{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertModel\n",
    "from transformers import BertTokenizer\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "\n",
    "from pan20 import fake\n",
    "from torch.nn import DataParallel\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Load dataset\n",
    "\n",
    "df = fake.load_data()\n",
    "truth = {x['author']: x['label'] for x in fake.load_truth()}\n",
    "df['label'] = df.author.apply(lambda x: truth[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-large-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoded_data = tokenizer.batch_encode_plus(df['tweet'], pad_to_max_length=True, add_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertModel(\n",
       "  (embeddings): BertEmbeddings(\n",
       "    (word_embeddings): Embedding(30522, 1024, padding_idx=0)\n",
       "    (position_embeddings): Embedding(512, 1024)\n",
       "    (token_type_embeddings): Embedding(2, 1024)\n",
       "    (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): BertEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (2): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (3): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (4): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (5): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (6): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (7): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (8): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (9): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (10): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (11): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (12): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (13): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (14): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (15): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (16): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (17): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (18): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (19): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (20): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (21): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (22): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (23): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): BertPooler(\n",
       "    (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model= BertModel.from_pretrained('bert-large-uncased')\n",
    "#model = DataParallel(model)\n",
    "model = model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with torch.no_grad():\n",
    "\n",
    "#     input_ids = torch.tensor(encoded_data[\"input_ids\"])\n",
    "#     outputs = model(input_ids)\n",
    "#     last_hidden_states = outputs[0]\n",
    "#     sentencevec = last_hidden_states[:,0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "class PanDataset(Dataset):\n",
    "    def __init__(self, data, tokenizer):\n",
    "        self.data = data\n",
    "        self.tokenizer = tokenizer\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        text, label = self.data.iloc[idx, :].values\n",
    "        label_tensors = torch.tensor(label)\n",
    "        \n",
    "        word_pieces = [\"[CLS]\"]\n",
    "        tokens = self.tokenizer.tokenize(text)\n",
    "        word_pieces += tokens + [\"[SEP]\"]\n",
    "        \n",
    "        ids = self.tokenizer.convert_tokens_to_ids(word_pieces)\n",
    "        tokens_tensors = torch.tensor(ids)\n",
    "        \n",
    "        return tokens_tensors, label_tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    \n",
    "    tokens_tensors = [data[0] for data in batch]\n",
    "    if batch[0][1] is not None:\n",
    "        label_ids = torch.stack([label[1] for label in batch])\n",
    "    else:\n",
    "        label_ids = None\n",
    "\n",
    "    tokens_tensors = pad_sequence(tokens_tensors, batch_first=True)\n",
    "        \n",
    "    masks_tensors = torch.zeros(tokens_tensors.shape, dtype=torch.long)\n",
    "    masks_tensors = masks_tensors.masked_fill(tokens_tensors != 0, 1)\n",
    "    \n",
    "    return tokens_tensors, masks_tensors, label_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = df.drop('author', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = PanDataset(df_test, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "testloader = DataLoader(dataset, batch_size=1, shuffle=False, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "u_vectors = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        tokens_tensors, masks_tensors = data[:2]\n",
    "        tokens_tensors = tokens_tensors.to(device)\n",
    "        masks_tensors = masks_tensors.to(device)\n",
    "        outputs = model(input_ids=tokens_tensors,\n",
    "                        token_type_ids=None,\n",
    "                        attention_mask=masks_tensors)\n",
    "        \n",
    "        u_vectors.append(outputs[0][:,0,:].cpu().squeeze().numpy())\n",
    "\n",
    "        del tokens_tensors\n",
    "        del masks_tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30000"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(u_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(u_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_vectors = []\n",
    "\n",
    "for i in range(0, 30000, 100):\n",
    "    #sum_vectors.append(list(map(sum, zip(*u_vectors[i:i+100]))))\n",
    "    sum_vectors.append(np.sum(u_vectors[i:i+100], axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_vectors = []\n",
    "\n",
    "for i in range(0, 30000, 100):\n",
    "    #sum_vectors.append(list(map(sum, zip(*u_vectors[i:i+100]))))\n",
    "    avg_vectors.append(np.average(u_vectors[i:i+100], axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'8vp74g6kssomu1a6akix6y3hqy6552t7'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.author[100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "## get original information\n",
    "\n",
    "new_df = {\n",
    "    'author': [],\n",
    "    'label': []}\n",
    "\n",
    "for i in range(0, 30000, 100):\n",
    "    new_df['author'].append(df.author[i])\n",
    "    new_df['label'].append(df.label[i])\n",
    "\n",
    "\n",
    "new_df = pd.DataFrame(new_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    150\n",
       "0    150\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_val_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/usr/local/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/usr/local/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/usr/local/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/usr/local/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/usr/local/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/usr/local/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectors by sum: [0.71666667 0.7        0.71666667 0.63333333 0.7       ]\n",
      "Vectors by sum: 0.6933333333333334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/usr/local/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/usr/local/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/usr/local/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/usr/local/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectors by avg: [0.71666667 0.66666667 0.76666667 0.66666667 0.66666667]\n",
      "Vectors by avg: 0.6966666666666665\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/usr/local/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/usr/local/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clf = LogisticRegression()\n",
    "scores = cross_val_score(clf, sum_vectors, new_df['label'], cv=5)\n",
    "print(\"Vectors by sum:\", scores)\n",
    "print(\"Vectors by sum:\", np.mean(scores))\n",
    "\n",
    "clf = LogisticRegression()\n",
    "scores = cross_val_score(clf, avg_vectors, new_df['label'], cv=5)\n",
    "proba = cross_val_predict(clf, avg_vectors, new_df['label'], cv=5, method='predict_proba')\n",
    "print(\"Vectors by avg:\", scores)\n",
    "print(\"Vectors by avg:\", np.mean(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_spreader = []\n",
    "for i in range(300):\n",
    "    is_spreader.append(proba[i][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df_all = new_df.assign(probability=is_spreader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_s = []\n",
    "for i in range(300):\n",
    "    if proba[i][0]>proba[i][1]:\n",
    "        pred_s.append(0)\n",
    "    else:\n",
    "        pred_s.append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(pred_s == new_df_all['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectors by sum: [0.73333333 0.65       0.68333333 0.6        0.65      ]\n",
      "Vectors by sum: 0.6633333333333333\n",
      "Vectors by avg: [0.73333333 0.65       0.68333333 0.6        0.65      ]\n",
      "Vectors by avg: 0.6633333333333333\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "clf = GaussianNB()\n",
    "s_scores = cross_val_score(clf, sum_vectors, new_df['label'], cv=5)\n",
    "print(\"Vectors by sum:\", s_scores)\n",
    "print(\"Vectors by sum:\", np.mean(s_scores))\n",
    "\n",
    "clf = GaussianNB()\n",
    "a_scores = cross_val_score(clf, avg_vectors, new_df['label'], cv=5)\n",
    "print(\"Vectors by avg:\", a_scores)\n",
    "print(\"Vectors by avg:\", np.mean(a_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectors by sum: [0.7        0.7        0.73333333 0.66666667 0.7       ]\n",
      "Vectors by sum: 0.7\n",
      "Vectors by avg: [0.71666667 0.68333333 0.73333333 0.7        0.68333333]\n",
      "Vectors by avg: 0.7033333333333334\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "svc = svm.SVC(C=0.9, kernel='linear')\n",
    "s_scores = cross_val_score(svc, sum_vectors, new_df['label'], cv=5)\n",
    "print(\"Vectors by sum:\", s_scores)\n",
    "print(\"Vectors by sum:\", np.mean(s_scores))\n",
    "\n",
    "svc = svm.SVC(C=1000, degree=1, kernel='sigmoid', gamma=0.0009, probability=True)\n",
    "#svc = svm.SVC(C=1000, degree=100, kernel='rbf', gamma=0.0009, probability=True)\n",
    "a_scores = cross_val_score(svc, avg_vectors, new_df['label'], cv=5)\n",
    "proba = cross_val_predict(svc, avg_vectors, new_df['label'], cv=5, method='predict_proba')\n",
    "print(\"Vectors by avg:\", a_scores)\n",
    "print(\"Vectors by avg:\", np.mean(a_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df_all.to_csv('bert_large_svm_0.7.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df_all.to_csv('bert_encoded.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectors by sum: [0.68333333 0.68333333 0.75       0.66666667 0.66666667]\n",
      "Vectors by sum: 0.69\n",
      "Vectors by avg: [0.68333333 0.68333333 0.7        0.7        0.6       ]\n",
      "Vectors by avg: 0.6733333333333333\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=200, max_depth=5)\n",
    "s_scores = cross_val_score(rf, sum_vectors, new_df['label'], cv=5)\n",
    "print(\"Vectors by sum:\", s_scores)\n",
    "print(\"Vectors by sum:\", np.mean(s_scores))\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=200, max_depth=5)\n",
    "a_scores = cross_val_score(rf, avg_vectors, new_df['label'], cv=5)\n",
    "print(\"Vectors by avg:\", a_scores)\n",
    "print(\"Vectors by avg:\", np.mean(a_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1000, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=1, gamma=0.0009, kernel='sigmoid',\n",
       "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
       "    verbose=False)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## input all data for training\n",
    "\n",
    "from sklearn import svm\n",
    "\n",
    "svc = svm.SVC(C=1000, degree=1, kernel='sigmoid', gamma=0.0009, probability=True)\n",
    "#svc = svm.SVC(C=1000, degree=100, kernel='rbf', gamma=0.0009, probability=True)\n",
    "svc.fit(avg_vectors, new_df['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.89"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(new_df['label']== svc.predict(avg_vectors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['pan20/fake/bert-large-sigmoid.model']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "joblib.dump(svc, 'pan20/fake/bert-large-sigmoid.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.29617567, 0.70382433],\n",
       "       [0.5       , 0.5       ],\n",
       "       [0.57803379, 0.42196621],\n",
       "       [0.58956482, 0.41043518],\n",
       "       [0.31739315, 0.68260685],\n",
       "       [0.39742677, 0.60257323],\n",
       "       [0.40111351, 0.59888649],\n",
       "       [0.54975952, 0.45024048],\n",
       "       [0.58789156, 0.41210844],\n",
       "       [0.62249247, 0.37750753],\n",
       "       [0.48036478, 0.51963522],\n",
       "       [0.50686205, 0.49313795],\n",
       "       [0.68985105, 0.31014895],\n",
       "       [0.72996014, 0.27003986],\n",
       "       [0.58573696, 0.41426304],\n",
       "       [0.53677975, 0.46322025],\n",
       "       [0.25408683, 0.74591317],\n",
       "       [0.47761078, 0.52238922],\n",
       "       [0.38404175, 0.61595825],\n",
       "       [0.2666539 , 0.7333461 ],\n",
       "       [0.49039304, 0.50960696],\n",
       "       [0.73768677, 0.26231323],\n",
       "       [0.30264598, 0.69735402],\n",
       "       [0.78917744, 0.21082256],\n",
       "       [0.68784775, 0.31215225],\n",
       "       [0.89308839, 0.10691161],\n",
       "       [0.19344285, 0.80655715],\n",
       "       [0.3244257 , 0.6755743 ],\n",
       "       [0.46457124, 0.53542876],\n",
       "       [0.56614084, 0.43385916],\n",
       "       [0.12781936, 0.87218064],\n",
       "       [0.58725785, 0.41274215],\n",
       "       [0.62728502, 0.37271498],\n",
       "       [0.77324054, 0.22675946],\n",
       "       [0.31952227, 0.68047773],\n",
       "       [0.41663303, 0.58336697],\n",
       "       [0.66130598, 0.33869402],\n",
       "       [0.90204333, 0.09795667],\n",
       "       [0.39415796, 0.60584204],\n",
       "       [0.34523629, 0.65476371],\n",
       "       [0.88499101, 0.11500899],\n",
       "       [0.20587779, 0.79412221],\n",
       "       [0.47935051, 0.52064949],\n",
       "       [0.71448166, 0.28551834],\n",
       "       [0.70936963, 0.29063037],\n",
       "       [0.46248487, 0.53751513],\n",
       "       [0.40011385, 0.59988615],\n",
       "       [0.39197182, 0.60802818],\n",
       "       [0.64738568, 0.35261432],\n",
       "       [0.40280052, 0.59719948],\n",
       "       [0.26287703, 0.73712297],\n",
       "       [0.41645494, 0.58354506],\n",
       "       [0.72173439, 0.27826561],\n",
       "       [0.61742162, 0.38257838],\n",
       "       [0.61418528, 0.38581472],\n",
       "       [0.390857  , 0.609143  ],\n",
       "       [0.60814357, 0.39185643],\n",
       "       [0.67104256, 0.32895744],\n",
       "       [0.42236113, 0.57763887],\n",
       "       [0.35804427, 0.64195573],\n",
       "       [0.43296176, 0.56703824],\n",
       "       [0.62660594, 0.37339406],\n",
       "       [0.52298357, 0.47701643],\n",
       "       [0.20674128, 0.79325872],\n",
       "       [0.86966592, 0.13033408],\n",
       "       [0.1217596 , 0.8782404 ],\n",
       "       [0.40524163, 0.59475837],\n",
       "       [0.53994705, 0.46005295],\n",
       "       [0.82030057, 0.17969943],\n",
       "       [0.74762382, 0.25237618],\n",
       "       [0.20674108, 0.79325892],\n",
       "       [0.2159773 , 0.7840227 ],\n",
       "       [0.62994944, 0.37005056],\n",
       "       [0.37832328, 0.62167672],\n",
       "       [0.19436504, 0.80563496],\n",
       "       [0.69779998, 0.30220002],\n",
       "       [0.2246967 , 0.7753033 ],\n",
       "       [0.24890331, 0.75109669],\n",
       "       [0.15356085, 0.84643915],\n",
       "       [0.26046978, 0.73953022],\n",
       "       [0.38049395, 0.61950605],\n",
       "       [0.34311994, 0.65688006],\n",
       "       [0.20674115, 0.79325885],\n",
       "       [0.34758224, 0.65241776],\n",
       "       [0.55427852, 0.44572148],\n",
       "       [0.88672746, 0.11327254],\n",
       "       [0.36410942, 0.63589058],\n",
       "       [0.76079193, 0.23920807],\n",
       "       [0.82584791, 0.17415209],\n",
       "       [0.60932239, 0.39067761],\n",
       "       [0.29220846, 0.70779154],\n",
       "       [0.43458646, 0.56541354],\n",
       "       [0.76450334, 0.23549666],\n",
       "       [0.21931508, 0.78068492],\n",
       "       [0.83322152, 0.16677848],\n",
       "       [0.7056321 , 0.2943679 ],\n",
       "       [0.52810329, 0.47189671],\n",
       "       [0.49384377, 0.50615623],\n",
       "       [0.63266263, 0.36733737],\n",
       "       [0.72808856, 0.27191144],\n",
       "       [0.83804757, 0.16195243],\n",
       "       [0.36979837, 0.63020163],\n",
       "       [0.2470681 , 0.7529319 ],\n",
       "       [0.43418169, 0.56581831],\n",
       "       [0.34490563, 0.65509437],\n",
       "       [0.34614766, 0.65385234],\n",
       "       [0.39537972, 0.60462028],\n",
       "       [0.62932652, 0.37067348],\n",
       "       [0.69293243, 0.30706757],\n",
       "       [0.32085545, 0.67914455],\n",
       "       [0.61424628, 0.38575372],\n",
       "       [0.65463195, 0.34536805],\n",
       "       [0.81048024, 0.18951976],\n",
       "       [0.55221777, 0.44778223],\n",
       "       [0.68204306, 0.31795694],\n",
       "       [0.26898432, 0.73101568],\n",
       "       [0.48787483, 0.51212517],\n",
       "       [0.40003538, 0.59996462],\n",
       "       [0.73519234, 0.26480766],\n",
       "       [0.80617712, 0.19382288],\n",
       "       [0.16260417, 0.83739583],\n",
       "       [0.40498268, 0.59501732],\n",
       "       [0.23891643, 0.76108357],\n",
       "       [0.84076709, 0.15923291],\n",
       "       [0.35255709, 0.64744291],\n",
       "       [0.64012704, 0.35987296],\n",
       "       [0.4443868 , 0.5556132 ],\n",
       "       [0.52170597, 0.47829403],\n",
       "       [0.72966351, 0.27033649],\n",
       "       [0.19378728, 0.80621272],\n",
       "       [0.36609731, 0.63390269],\n",
       "       [0.36925063, 0.63074937],\n",
       "       [0.1857071 , 0.8142929 ],\n",
       "       [0.28437634, 0.71562366],\n",
       "       [0.31384254, 0.68615746],\n",
       "       [0.12191314, 0.87808686],\n",
       "       [0.80469238, 0.19530762],\n",
       "       [0.60543187, 0.39456813],\n",
       "       [0.09596097, 0.90403903],\n",
       "       [0.42583674, 0.57416326],\n",
       "       [0.82763816, 0.17236184],\n",
       "       [0.74193901, 0.25806099],\n",
       "       [0.67219692, 0.32780308],\n",
       "       [0.80249907, 0.19750093],\n",
       "       [0.14059196, 0.85940804],\n",
       "       [0.74573197, 0.25426803],\n",
       "       [0.85657502, 0.14342498],\n",
       "       [0.73118122, 0.26881878],\n",
       "       [0.83257309, 0.16742691],\n",
       "       [0.367178  , 0.632822  ],\n",
       "       [0.48553647, 0.51446353],\n",
       "       [0.60453723, 0.39546277],\n",
       "       [0.66742173, 0.33257827],\n",
       "       [0.83308616, 0.16691384],\n",
       "       [0.19221418, 0.80778582],\n",
       "       [0.42675219, 0.57324781],\n",
       "       [0.68277482, 0.31722518],\n",
       "       [0.17117465, 0.82882535],\n",
       "       [0.46542728, 0.53457272],\n",
       "       [0.56869188, 0.43130812],\n",
       "       [0.69123914, 0.30876086],\n",
       "       [0.39623511, 0.60376489],\n",
       "       [0.28311048, 0.71688952],\n",
       "       [0.51209281, 0.48790719],\n",
       "       [0.56926315, 0.43073685],\n",
       "       [0.87730607, 0.12269393],\n",
       "       [0.2592812 , 0.7407188 ],\n",
       "       [0.60933483, 0.39066517],\n",
       "       [0.47581335, 0.52418665],\n",
       "       [0.6503698 , 0.3496302 ],\n",
       "       [0.34182863, 0.65817137],\n",
       "       [0.32190876, 0.67809124],\n",
       "       [0.4220751 , 0.5779249 ],\n",
       "       [0.71318796, 0.28681204],\n",
       "       [0.69914434, 0.30085566],\n",
       "       [0.75987348, 0.24012652],\n",
       "       [0.17495461, 0.82504539],\n",
       "       [0.17698835, 0.82301165],\n",
       "       [0.24388538, 0.75611462],\n",
       "       [0.42844413, 0.57155587],\n",
       "       [0.48059192, 0.51940808],\n",
       "       [0.76953351, 0.23046649],\n",
       "       [0.26939622, 0.73060378],\n",
       "       [0.65376405, 0.34623595],\n",
       "       [0.24848925, 0.75151075],\n",
       "       [0.59378312, 0.40621688],\n",
       "       [0.42275926, 0.57724074],\n",
       "       [0.46296698, 0.53703302],\n",
       "       [0.12932072, 0.87067928],\n",
       "       [0.46570337, 0.53429663],\n",
       "       [0.55978543, 0.44021457],\n",
       "       [0.15235829, 0.84764171],\n",
       "       [0.53144014, 0.46855986],\n",
       "       [0.65390086, 0.34609914],\n",
       "       [0.34381268, 0.65618732],\n",
       "       [0.76276854, 0.23723146],\n",
       "       [0.85256266, 0.14743734],\n",
       "       [0.52306485, 0.47693515],\n",
       "       [0.52669267, 0.47330733],\n",
       "       [0.46242369, 0.53757631],\n",
       "       [0.7008366 , 0.2991634 ],\n",
       "       [0.63420762, 0.36579238],\n",
       "       [0.21975584, 0.78024416],\n",
       "       [0.12691881, 0.87308119],\n",
       "       [0.72148002, 0.27851998],\n",
       "       [0.59618508, 0.40381492],\n",
       "       [0.57452923, 0.42547077],\n",
       "       [0.78932826, 0.21067174],\n",
       "       [0.2961917 , 0.7038083 ],\n",
       "       [0.62272423, 0.37727577],\n",
       "       [0.25326938, 0.74673062],\n",
       "       [0.32869302, 0.67130698],\n",
       "       [0.44628466, 0.55371534],\n",
       "       [0.72258235, 0.27741765],\n",
       "       [0.50774549, 0.49225451],\n",
       "       [0.74650029, 0.25349971],\n",
       "       [0.36236668, 0.63763332],\n",
       "       [0.82337013, 0.17662987],\n",
       "       [0.47123684, 0.52876316],\n",
       "       [0.24394586, 0.75605414],\n",
       "       [0.07696119, 0.92303881],\n",
       "       [0.69133218, 0.30866782],\n",
       "       [0.4461626 , 0.5538374 ],\n",
       "       [0.81252059, 0.18747941],\n",
       "       [0.63256085, 0.36743915],\n",
       "       [0.26939636, 0.73060364],\n",
       "       [0.65442664, 0.34557336],\n",
       "       [0.20344192, 0.79655808],\n",
       "       [0.41870332, 0.58129668],\n",
       "       [0.6066131 , 0.3933869 ],\n",
       "       [0.66282633, 0.33717367],\n",
       "       [0.68644193, 0.31355807],\n",
       "       [0.52624171, 0.47375829],\n",
       "       [0.63133751, 0.36866249],\n",
       "       [0.46175712, 0.53824288],\n",
       "       [0.93714509, 0.06285491],\n",
       "       [0.64442071, 0.35557929],\n",
       "       [0.50556371, 0.49443629],\n",
       "       [0.67189696, 0.32810304],\n",
       "       [0.92744108, 0.07255892],\n",
       "       [0.44928259, 0.55071741],\n",
       "       [0.50724731, 0.49275269],\n",
       "       [0.44816891, 0.55183109],\n",
       "       [0.17970132, 0.82029868],\n",
       "       [0.80630644, 0.19369356],\n",
       "       [0.12466696, 0.87533304],\n",
       "       [0.41192752, 0.58807248],\n",
       "       [0.22237825, 0.77762175],\n",
       "       [0.95828766, 0.04171234],\n",
       "       [0.72146019, 0.27853981],\n",
       "       [0.60916994, 0.39083006],\n",
       "       [0.88389252, 0.11610748],\n",
       "       [0.4248785 , 0.5751215 ],\n",
       "       [0.52586696, 0.47413304],\n",
       "       [0.28860458, 0.71139542],\n",
       "       [0.5       , 0.5       ],\n",
       "       [0.88998832, 0.11001168],\n",
       "       [0.71706697, 0.28293303],\n",
       "       [0.30161278, 0.69838722],\n",
       "       [0.44644001, 0.55355999],\n",
       "       [0.3417184 , 0.6582816 ],\n",
       "       [0.33961619, 0.66038381],\n",
       "       [0.87508246, 0.12491754],\n",
       "       [0.16854098, 0.83145902],\n",
       "       [0.29222951, 0.70777049],\n",
       "       [0.48483991, 0.51516009],\n",
       "       [0.10202246, 0.89797754],\n",
       "       [0.60509681, 0.39490319],\n",
       "       [0.47414038, 0.52585962],\n",
       "       [0.60119871, 0.39880129],\n",
       "       [0.7477365 , 0.2522635 ],\n",
       "       [0.80294333, 0.19705667],\n",
       "       [0.52226017, 0.47773983],\n",
       "       [0.35999847, 0.64000153],\n",
       "       [0.12743123, 0.87256877],\n",
       "       [0.62254774, 0.37745226],\n",
       "       [0.57976712, 0.42023288],\n",
       "       [0.29837473, 0.70162527],\n",
       "       [0.57567585, 0.42432415],\n",
       "       [0.1272812 , 0.8727188 ],\n",
       "       [0.5107551 , 0.4892449 ],\n",
       "       [0.16676211, 0.83323789],\n",
       "       [0.6474936 , 0.3525064 ],\n",
       "       [0.53003146, 0.46996854],\n",
       "       [0.48877636, 0.51122364],\n",
       "       [0.17005447, 0.82994553],\n",
       "       [0.33611314, 0.66388686],\n",
       "       [0.49449571, 0.50550429],\n",
       "       [0.35345149, 0.64654851],\n",
       "       [0.5658909 , 0.4341091 ],\n",
       "       [0.63697967, 0.36302033],\n",
       "       [0.60607191, 0.39392809],\n",
       "       [0.58149833, 0.41850167],\n",
       "       [0.56238209, 0.43761791],\n",
       "       [0.88319705, 0.11680295],\n",
       "       [0.69393495, 0.30606505],\n",
       "       [0.30500203, 0.69499797],\n",
       "       [0.20349391, 0.79650609],\n",
       "       [0.64918289, 0.35081711],\n",
       "       [0.20179547, 0.79820453]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
