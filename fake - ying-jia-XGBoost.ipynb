{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import metrics, model_selection, preprocessing\n",
    "import xgboost as xgb\n",
    "\n",
    "from pan20 import util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/fake/feats.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_X_y(cols=None, no_cols=None):\n",
    "    X = df.groupby(['author', 'label']).mean().reset_index()\n",
    "    y = X.label.values\n",
    "    a = list(X.author.values)\n",
    "    X.drop(columns=['author', 'n'], inplace=True)\n",
    "    if cols:\n",
    "        X = X.loc[:, [c in cols for c in X.columns]]\n",
    "    elif no_cols:\n",
    "        X = X.loc[:, [c not in no_cols for c in X.columns]]\n",
    "    else:\n",
    "        X = X.loc[:, [c != 'label' for c in X.columns]]\n",
    "    feat_dict = util.IxDict(X.columns)\n",
    "    # normalize features to be between 0 and 1\n",
    "    x = X.values\n",
    "    min_max_scaler = preprocessing.MinMaxScaler()\n",
    "    X = min_max_scaler.fit_transform(x)\n",
    "    return X, y, feat_dict, a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "feats = [\n",
    "    'adverbs', \n",
    "    'impersonal_pronouns',\n",
    "    'personal_pronouns', \n",
    "    'function_words',\n",
    "    'avg_bf', \n",
    "    'max_np_height', \n",
    "    'max_vp_height',\n",
    "    'senti', \n",
    "    'senti_neg', \n",
    "    'anger', \n",
    "    'distrust'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y, feat_dict, a = get_X_y(feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.7/site-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator SVC from version 0.22.2.post1 when using version 0.22.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/usr/local/anaconda3/lib/python3.7/site-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator DecisionTreeClassifier from version 0.22.2.post1 when using version 0.22.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/usr/local/anaconda3/lib/python3.7/site-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator RandomForestClassifier from version 0.22.2.post1 when using version 0.22.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/usr/local/anaconda3/lib/python3.7/site-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator SVC from version 0.22.2.post1 when using version 0.22.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    }
   ],
   "source": [
    "svc = joblib.load('pan20/fake/svc.model')\n",
    "rf = joblib.load('pan20/fake/rf.model')\n",
    "nb = joblib.load('pan20/fake/nb.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_svc = list(np.exp(svc.predict_log_proba(X))[:, 1])\n",
    "p_rf = list(np.exp(rf.predict_log_proba(X))[:, 1])\n",
    "p_nb = list(np.exp(nb.predict_log_proba(X))[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "#p_bert = pd.read_csv('tmp/bert_encoded.csv')\n",
    "#p_bert = pd.read_csv('tmp/bert_large_svm_070.csv')\n",
    "p_bert = pd.read_csv('tmp/bert_large_svm_070.csv')\n",
    "p_roberta = pd.read_csv('tmp/roberta_svm_071.csv')\n",
    "#p_electra = pd.read_csv('tmp/electra_base_svm_066.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "#p_bert.drop(columns=['label'], inplace=True)\n",
    "p_roberta.drop(columns=['label'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_in = pd.DataFrame({\n",
    "    'author': a,\n",
    "    'label': y,\n",
    "    'svc': p_svc,\n",
    "    'rf': p_rf,\n",
    "    'nb': p_nb,\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_in.set_index('author')\n",
    "p_bert.set_index('author')\n",
    "xgb_in = xgb_in.merge(p_bert, on='author')\n",
    "xgb_in = xgb_in.merge(p_roberta, on='author')\n",
    "#xgb_in = xgb_in.merge(p_electra, on='author')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>label_x</th>\n",
       "      <th>svc</th>\n",
       "      <th>rf</th>\n",
       "      <th>nb</th>\n",
       "      <th>label_y</th>\n",
       "      <th>probability_x</th>\n",
       "      <th>probability_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>06ct0t68y1acizh9eow3g5rhancrppr8</td>\n",
       "      <td>1</td>\n",
       "      <td>0.714161</td>\n",
       "      <td>0.867710</td>\n",
       "      <td>0.706297</td>\n",
       "      <td>1</td>\n",
       "      <td>0.941727</td>\n",
       "      <td>0.686610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>071nxc49ihpd0jlfmvn2lghtayy3b5n9</td>\n",
       "      <td>0</td>\n",
       "      <td>0.595813</td>\n",
       "      <td>0.445694</td>\n",
       "      <td>0.591051</td>\n",
       "      <td>0</td>\n",
       "      <td>0.842279</td>\n",
       "      <td>0.736981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>09py5qescynpnnckmzueqzr2y49moh1o</td>\n",
       "      <td>0</td>\n",
       "      <td>0.511316</td>\n",
       "      <td>0.361854</td>\n",
       "      <td>0.509568</td>\n",
       "      <td>0</td>\n",
       "      <td>0.429073</td>\n",
       "      <td>0.244102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0dwovd7nj6yg9m795ng2c629me0ccmrh</td>\n",
       "      <td>0</td>\n",
       "      <td>0.475750</td>\n",
       "      <td>0.260155</td>\n",
       "      <td>0.475279</td>\n",
       "      <td>0</td>\n",
       "      <td>0.308907</td>\n",
       "      <td>0.356693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0ibi364m7i7l01xi4xqafyathrmrrnll</td>\n",
       "      <td>1</td>\n",
       "      <td>0.680197</td>\n",
       "      <td>0.752722</td>\n",
       "      <td>0.673100</td>\n",
       "      <td>1</td>\n",
       "      <td>0.612581</td>\n",
       "      <td>0.673037</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             author  label_x       svc        rf        nb  \\\n",
       "0  06ct0t68y1acizh9eow3g5rhancrppr8        1  0.714161  0.867710  0.706297   \n",
       "1  071nxc49ihpd0jlfmvn2lghtayy3b5n9        0  0.595813  0.445694  0.591051   \n",
       "2  09py5qescynpnnckmzueqzr2y49moh1o        0  0.511316  0.361854  0.509568   \n",
       "3  0dwovd7nj6yg9m795ng2c629me0ccmrh        0  0.475750  0.260155  0.475279   \n",
       "4  0ibi364m7i7l01xi4xqafyathrmrrnll        1  0.680197  0.752722  0.673100   \n",
       "\n",
       "   label_y  probability_x  probability_y  \n",
       "0        1       0.941727       0.686610  \n",
       "1        0       0.842279       0.736981  \n",
       "2        0       0.429073       0.244102  \n",
       "3        0       0.308907       0.356693  \n",
       "4        1       0.612581       0.673037  "
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_in.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_in.drop(columns=['label_y'], inplace=True)\n",
    "#xgb_in.rename(columns={'label_x': 'label', 'probability': 'bert'}, inplace=True)\n",
    "xgb_in.rename(columns={'label_x': 'label', 'probability_x': 'bert', 'probability_y': 'roberta'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_in.to_csv('tmp/xgb_in.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_txt(feats, file_path, test=False):\n",
    "    with open(file_path, 'w+') as f:\n",
    "        for _, x in feats.iterrows():\n",
    "            if not test:\n",
    "                row = f'{x.label} 0:{x.svc} 1:{x.rf} 2:{x.nb} 3:{x.bert} 4:{x.roberta}\\n'\n",
    "            else:\n",
    "                row = f'0:{x.svc} 1:{x.rf} 2:{x.nb} 3:{x.bert} 4:{x.roberta}\\n'\n",
    "            f.write(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_txt(feats, file_path, test=False):\n",
    "    with open(file_path, 'w+') as f:\n",
    "        for _, x in feats.iterrows():\n",
    "            if not test:\n",
    "                row = f'{x.label} 0:{x.svc} 1:{x.rf} 2:{x.nb}\\n'\n",
    "            else:\n",
    "                row = f'0:{x.svc} 1:{x.rf} 2:{x.nb}\\n'\n",
    "            f.write(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:57:12] 240x5 matrix with 1200 entries loaded from tmp/xgb_train.txt\n",
      "[15:57:12] 60x5 matrix with 240 entries loaded from tmp/xgb_test.txt\n",
      "[15:57:12] 240x5 matrix with 1200 entries loaded from tmp/xgb_train.txt\n",
      "[15:57:12] 60x5 matrix with 240 entries loaded from tmp/xgb_test.txt\n",
      "[15:57:12] 240x5 matrix with 1200 entries loaded from tmp/xgb_train.txt\n",
      "[15:57:12] 60x5 matrix with 240 entries loaded from tmp/xgb_test.txt\n",
      "[15:57:12] 240x5 matrix with 1200 entries loaded from tmp/xgb_train.txt\n",
      "[15:57:12] 60x5 matrix with 240 entries loaded from tmp/xgb_test.txt\n",
      "[15:57:12] 240x5 matrix with 1200 entries loaded from tmp/xgb_train.txt\n",
      "[15:57:12] 60x5 matrix with 240 entries loaded from tmp/xgb_test.txt\n",
      "[0.95, 0.9166666666666666, 0.9, 0.8666666666666667, 0.8833333333333333]\n",
      "0.9033333333333333\n"
     ]
    }
   ],
   "source": [
    "accs = []\n",
    "skf = model_selection.StratifiedKFold(n_splits=5)\n",
    "for tr_ix, ts_ix in skf.split(X, y):\n",
    "    tr = xgb_in.iloc[tr_ix]\n",
    "    ts = xgb_in.iloc[ts_ix]\n",
    "    to_txt(tr, 'tmp/xgb_train.txt')\n",
    "    to_txt(ts, 'tmp/xgb_test.txt', test=True)\n",
    "    dtrain = xgb.DMatrix('tmp/xgb_train.txt')\n",
    "    dtest = xgb.DMatrix('tmp/xgb_test.txt')\n",
    "    params = {\n",
    "        'max_depth': 2,\n",
    "        'eta': 1,\n",
    "        'objective': 'binary:logistic',\n",
    "    }\n",
    "    num_round = 2\n",
    "    bst = xgb.train(params, dtrain, num_round)\n",
    "    preds = bst.predict(dtest)\n",
    "    preds = [p > 0.5 for p in preds]\n",
    "    accs.append(metrics.accuracy_score(ts.label.values, preds))\n",
    "print(accs)\n",
    "print(np.mean(accs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgbtr = xgb_in[['label', 'svc', 'rf', 'nb']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:11:33] 300x3 matrix with 900 entries loaded from tmp/xgb_train.txt\n",
      "[16:11:33] 300x3 matrix with 600 entries loaded from tmp/xgb_test.txt\n"
     ]
    }
   ],
   "source": [
    "to_txt(xgbtr, 'tmp/xgb_train.txt', test=False)\n",
    "to_txt(xgbtr, 'tmp/xgb_test.txt', test=True)\n",
    "dtrain = xgb.DMatrix('tmp/xgb_train.txt')\n",
    "dtest = xgb.DMatrix('tmp/xgb_test.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'max_depth': 3,\n",
    "    'eta': 1,\n",
    "    'objective': 'binary:logistic',\n",
    "}\n",
    "num_round = 2\n",
    "bst = xgb.train(params, dtrain, num_round)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9066666666666666"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "preds = bst.predict(dtest)\n",
    "preds = [p > 0.5 for p in preds]\n",
    "metrics.accuracy_score(xgb_in.label.values, preds)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "300"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(xgb_in.label.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "300"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
